{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804ca09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Traitement de AFRICA GLOBAL LOGISTICS (SDSC.ci)...\n",
      "🔍 Traitement de AIR LIQUIDE CI (SIVC.ci)...\n",
      "🔍 Traitement de BANK OF AFRICA BENIN (BOAB.bj)...\n",
      "🔍 Traitement de BANK OF AFRICA BURKINA FASO (BOABF.bf)...\n",
      "🔍 Traitement de BANK OF AFRICA CI (BOAC.ci)...\n",
      "🔍 Traitement de BANK OF AFRICA MALI (BOAM.ml)...\n",
      "🔍 Traitement de BANK OF AFRICA NIGER (BOAN.ne)...\n",
      "🔍 Traitement de BANK OF AFRICA SENEGAL (BOAS.sn)...\n",
      "🔍 Traitement de BERNABE (BNBC.ci)...\n",
      "🔍 Traitement de BICICI (BICC.ci)...\n",
      "🔍 Traitement de BRVM - AGRICULTURE (BRVMAG)...\n",
      "🔍 Traitement de BRVM - AUTRES SECTEURS (BRVMAS)...\n",
      "🔍 Traitement de BRVM - CONSOMMATION DE BASE (BRVM-CB)...\n",
      "🔍 Traitement de BRVM - CONSOMMATION DISCRETIONNAIRE (BRVM-CD)...\n",
      "🔍 Traitement de BRVM - DISTRIBUTION (BRVMDI)...\n",
      "🔍 Traitement de BRVM - ENERGIE (BRVM-EN)...\n",
      "🔍 Traitement de BRVM - FINANCE (BRVMFI)...\n",
      "🔍 Traitement de BRVM - INDUSTRIE (BRVMIN)...\n",
      "🔍 Traitement de BRVM - INDUSTRIELS (BRVM-IN)...\n",
      "🔍 Traitement de BRVM - PRESTIGE (BRVMPR)...\n",
      "🔍 Traitement de BRVM - PRINCIPAL (BRVMPA)...\n",
      "🔍 Traitement de BRVM - SERVICES FINANCIERS (BRVM-SF)...\n",
      "🔍 Traitement de BRVM - SERVICES PUBLICS (BRVMSP)...\n",
      "🔍 Traitement de BRVM - SERVICES PUBLICS (BRVM-SP)...\n",
      "🔍 Traitement de BRVM - TELECOMMUNICATIONS (BRVM-TEL)...\n",
      "🔍 Traitement de BRVM - TRANSPORT (BRVMTR)...\n",
      "🔍 Traitement de BRVM 30 (BRVM30)...\n",
      "🔍 Traitement de BRVM COMPOSITE (BRVMC)...\n",
      "🔍 Traitement de Capitalisation BRVM (CAPIBRVM)...\n",
      "🔍 Traitement de CFAO CI (CFAC.ci)...\n",
      "🔍 Traitement de CIE CI (CIEC.ci)...\n",
      "🔍 Traitement de CORIS BANK INTERNATIONAL BF (CBIBF.bf)...\n",
      "🔍 Traitement de CROWN SIEM (SEMC.ci)...\n",
      "🔍 Traitement de ECOBANK CI (ECOC.ci)...\n",
      "🔍 Traitement de ETI TG (ETIT.tg)...\n",
      "🔍 Traitement de FILTISAC CI (FTSC.ci)...\n",
      "🔍 Traitement de INDICE SIKAFINANCE (SIKAIDX)...\n",
      "🔍 Traitement de LOTERIE NATIONALE DU BENIN (LNBB.bj)...\n",
      "🔍 Traitement de MOVIS CI (SVOC.ci)...\n",
      "🔍 Traitement de NEI CEDA CI (NEIC.ci)...\n",
      "🔍 Traitement de NESTLE CI (NTLC.ci)...\n",
      "🔍 Traitement de NSIA BANQUE (NSBC.ci)...\n",
      "🔍 Traitement de ONATEL BF (ONTBF.bf)...\n",
      "🔍 Traitement de ORAGROUP TOGO (ORGT.tg)...\n",
      "🔍 Traitement de ORANGE CI (ORAC.ci)...\n",
      "🔍 Traitement de PALMCI (PALC.ci)...\n",
      "🔍 Traitement de SAFCA CI (SAFC.ci)...\n",
      "🔍 Traitement de SAPH CI (SPHC.ci)...\n",
      "🔍 Traitement de SERVAIR ABIDJAN CI (ABJC.ci)...\n",
      "🔍 Traitement de SETAO CI (STAC.ci)...\n",
      "🔍 Traitement de SGBCI (SGBC.ci)...\n",
      "🔍 Traitement de SICABLE CI (CABC.ci)...\n",
      "🔍 Traitement de SICOR (SICC.ci)...\n",
      "🔍 Traitement de SIKA TOTAL RETURN (SIKATR)...\n",
      "🔍 Traitement de SITAB (STBC.ci)...\n",
      "🔍 Traitement de SMB CI (SMBC.ci)...\n",
      "🔍 Traitement de SOCIETE IVOIRIENNE DE BANQUE CI (SIBC.ci)...\n",
      "🔍 Traitement de SODECI (SDCC.ci)...\n",
      "🔍 Traitement de SOGB (SOGC.ci)...\n",
      "🔍 Traitement de SOLIBRA CI (SLBC.ci)...\n",
      "🔍 Traitement de SONATEL (SNTS.sn)...\n",
      "🔍 Traitement de SUCRIVOIRE (SCRC.ci)...\n",
      "🔍 Traitement de TOTAL CI (TTLC.ci)...\n",
      "🔍 Traitement de TOTAL SENEGAL (TTLS.sn)...\n",
      "🔍 Traitement de TRACTAFRIC MOTORS CI (PRSC.ci)...\n",
      "🔍 Traitement de UNILEVER CI (UNLC.ci)...\n",
      "🔍 Traitement de UNIWAX CI (UNXC.ci)...\n",
      "🔍 Traitement de VIVO ENERGY CI (SHEC.ci)...\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Dates souhaitées\n",
    "date_from = \"15/01/2025\"\n",
    "date_to = \"11/04/2025\"\n",
    "\n",
    "# Lancement du navigateur\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Accès à la page principale\n",
    "driver.get(\"https://www.sikafinance.com/marches/historiques/SDSC.ci\")\n",
    "time.sleep(3)  # chargement initial\n",
    "\n",
    "# Récupération des options du menu déroulant\n",
    "select_element = wait.until(EC.presence_of_element_located((By.ID, \"dpShares\")))\n",
    "select_html = Select(select_element)\n",
    "\n",
    "# Récupération des paires (nom affiché, valeur)\n",
    "options = [(opt.text.strip(), opt.get_attribute(\"value\").strip())\n",
    "           for opt in select_html.options if opt.get_attribute(\"value\").strip()]\n",
    "\n",
    "# Stockage des données globales\n",
    "all_data = []\n",
    "\n",
    "for nom_action, valeur in options:\n",
    "    print(f\"🔍 Traitement de {nom_action} ({valeur})...\")\n",
    "\n",
    "    # Recharger la page pour éviter les conflits JS\n",
    "    driver.get(f\"https://www.sikafinance.com/marches/historiques/{valeur}\")\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        # Renseigner les dates\n",
    "        datefrom_input = wait.until(EC.presence_of_element_located((By.ID, \"datefrom\")))\n",
    "        dateto_input = driver.find_element(By.ID, \"dateto\")\n",
    "\n",
    "        datefrom_input.clear()\n",
    "        datefrom_input.send_keys(date_from)\n",
    "        dateto_input.clear()\n",
    "        dateto_input.send_keys(date_to)\n",
    "\n",
    "        # Cliquer sur \"OK\"\n",
    "        btn = driver.find_element(By.ID, \"btnChange\")\n",
    "        btn.click()\n",
    "\n",
    "        time.sleep(5)  # attendre le chargement des données\n",
    "\n",
    "        # Parser la page après clic\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        table = soup.find(\"table\", id=\"tblhistos\")\n",
    "\n",
    "        if table:\n",
    "            headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "            rows = []\n",
    "            for tr in table.find_all(\"tr\")[1:]:\n",
    "                cols = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "                if cols:\n",
    "                    rows.append(cols)\n",
    "\n",
    "            df = pd.DataFrame(rows, columns=headers)\n",
    "            df[\"Action\"] = nom_action\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"❌ Tableau non trouvé pour {nom_action}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Erreur pour {nom_action}: {e}\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "# Fermeture du navigateur\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248e9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connexion au cluster MongoDB Atlas\n",
    "client = MongoClient(\"mongodb+srv://amedbah2000:NQerjnFDI1xA8Dc1@cluster0.vbt1opf.mongodb.net/?retryWrites=true&w=majority\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données envoyées à MongoDB avec succès.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sélection de la base de données et de la collection\n",
    "db = client[\"sika_finance\"]\n",
    "collection = db[\"historique_actions\"]\n",
    "\n",
    "# Structure des données par action\n",
    "if all_data:\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    grouped = final_df.groupby(\"Action\")\n",
    "    for nom_action, df_action in grouped:\n",
    "        historique = df_action.drop(columns=[\"Action\"]).to_dict(orient=\"records\")\n",
    "\n",
    "        # Vérifie si l'action existe déjà dans la base\n",
    "        existing = collection.find_one({\"action\": nom_action})\n",
    "        if existing:\n",
    "            # Mettre à jour les données existantes (fusionner les historiques si besoin)\n",
    "            collection.update_one(\n",
    "                {\"action\": nom_action},\n",
    "                {\"$set\": {\"historique\": historique}}\n",
    "            )\n",
    "        else:\n",
    "            # Insérer une nouvelle action\n",
    "            collection.insert_one({\n",
    "                \"action\": nom_action,\n",
    "                \"historique\": historique\n",
    "            })\n",
    "\n",
    "    print(\"✅ Données envoyées à MongoDB avec succès.\")\n",
    "else:\n",
    "    print(\"❌ Aucune donnée à envoyer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5d052",
   "metadata": {},
   "source": [
    "## Actu et communiqué"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Scraping AFRICA GLOBAL LOGISTICS (SDSC.ci)...\n",
      "🔍 Scraping AIR LIQUIDE CI (SIVC.ci)...\n",
      "🔍 Scraping BANK OF AFRICA BENIN (BOAB.bj)...\n",
      "🔍 Scraping BANK OF AFRICA BURKINA FASO (BOABF.bf)...\n",
      "🔍 Scraping BANK OF AFRICA CI (BOAC.ci)...\n",
      "🔍 Scraping BANK OF AFRICA MALI (BOAM.ml)...\n",
      "🔍 Scraping BANK OF AFRICA NIGER (BOAN.ne)...\n",
      "🔍 Scraping BANK OF AFRICA SENEGAL (BOAS.sn)...\n",
      "🔍 Scraping BERNABE (BNBC.ci)...\n",
      "🔍 Scraping BICICI (BICC.ci)...\n",
      "🔍 Scraping BRVM - AGRICULTURE (BRVMAG)...\n",
      "🔍 Scraping BRVM - AUTRES SECTEURS (BRVMAS)...\n",
      "🔍 Scraping BRVM - CONSOMMATION DE BASE (BRVM-CB)...\n",
      "🔍 Scraping BRVM - CONSOMMATION DISCRETIONNAIRE (BRVM-CD)...\n",
      "🔍 Scraping BRVM - DISTRIBUTION (BRVMDI)...\n",
      "🔍 Scraping BRVM - ENERGIE (BRVM-EN)...\n",
      "🔍 Scraping BRVM - FINANCE (BRVMFI)...\n",
      "🔍 Scraping BRVM - INDUSTRIE (BRVMIN)...\n",
      "🔍 Scraping BRVM - INDUSTRIELS (BRVM-IN)...\n",
      "🔍 Scraping BRVM - PRESTIGE (BRVMPR)...\n",
      "🔍 Scraping BRVM - PRINCIPAL (BRVMPA)...\n",
      "🔍 Scraping BRVM - SERVICES FINANCIERS (BRVM-SF)...\n",
      "🔍 Scraping BRVM - SERVICES PUBLICS (BRVMSP)...\n",
      "🔍 Scraping BRVM - SERVICES PUBLICS (BRVM-SP)...\n",
      "🔍 Scraping BRVM - TELECOMMUNICATIONS (BRVM-TEL)...\n",
      "🔍 Scraping BRVM - TRANSPORT (BRVMTR)...\n",
      "🔍 Scraping BRVM 30 (BRVM30)...\n",
      "🔍 Scraping BRVM COMPOSITE (BRVMC)...\n",
      "🔍 Scraping Capitalisation BRVM (CAPIBRVM)...\n",
      "🔍 Scraping CFAO CI (CFAC.ci)...\n",
      "🔍 Scraping CIE CI (CIEC.ci)...\n",
      "🔍 Scraping CORIS BANK INTERNATIONAL BF (CBIBF.bf)...\n",
      "🔍 Scraping CROWN SIEM (SEMC.ci)...\n",
      "🔍 Scraping ECOBANK CI (ECOC.ci)...\n",
      "🔍 Scraping ETI TG (ETIT.tg)...\n",
      "🔍 Scraping FILTISAC CI (FTSC.ci)...\n",
      "🔍 Scraping INDICE SIKAFINANCE (SIKAIDX)...\n",
      "🔍 Scraping LOTERIE NATIONALE DU BENIN (LNBB.bj)...\n",
      "🔍 Scraping MOVIS CI (SVOC.ci)...\n",
      "🔍 Scraping NEI CEDA CI (NEIC.ci)...\n",
      "🔍 Scraping NESTLE CI (NTLC.ci)...\n",
      "🔍 Scraping NSIA BANQUE (NSBC.ci)...\n",
      "🔍 Scraping ONATEL BF (ONTBF.bf)...\n",
      "🔍 Scraping ORAGROUP TOGO (ORGT.tg)...\n",
      "🔍 Scraping ORANGE CI (ORAC.ci)...\n",
      "🔍 Scraping PALMCI (PALC.ci)...\n",
      "🔍 Scraping SAFCA CI (SAFC.ci)...\n",
      "🔍 Scraping SAPH CI (SPHC.ci)...\n",
      "🔍 Scraping SERVAIR ABIDJAN CI (ABJC.ci)...\n",
      "🔍 Scraping SETAO CI (STAC.ci)...\n",
      "🔍 Scraping SGBCI (SGBC.ci)...\n",
      "🔍 Scraping SICABLE CI (CABC.ci)...\n",
      "🔍 Scraping SICOR (SICC.ci)...\n",
      "🔍 Scraping SIKA TOTAL RETURN (SIKATR)...\n",
      "🔍 Scraping SITAB (STBC.ci)...\n",
      "🔍 Scraping SMB CI (SMBC.ci)...\n",
      "🔍 Scraping SOCIETE IVOIRIENNE DE BANQUE CI (SIBC.ci)...\n",
      "🔍 Scraping SODECI (SDCC.ci)...\n",
      "🔍 Scraping SOGB (SOGC.ci)...\n",
      "🔍 Scraping SOLIBRA CI (SLBC.ci)...\n",
      "🔍 Scraping SONATEL (SNTS.sn)...\n",
      "🔍 Scraping SUCRIVOIRE (SCRC.ci)...\n",
      "🔍 Scraping TOTAL CI (TTLC.ci)...\n",
      "🔍 Scraping TOTAL SENEGAL (TTLS.sn)...\n",
      "🔍 Scraping TRACTAFRIC MOTORS CI (PRSC.ci)...\n",
      "🔍 Scraping UNILEVER CI (UNLC.ci)...\n",
      "🔍 Scraping UNIWAX CI (UNXC.ci)...\n",
      "🔍 Scraping VIVO ENERGY CI (SHEC.ci)...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "base_url = \"https://www.sikafinance.com\"\n",
    "cot_url = base_url + \"/marches/cotation_\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# Étape 1 : Récupérer toutes les valeurs du sélecteur\n",
    "homepage = requests.get(cot_url + \"SDSC.ci\", headers=headers)\n",
    "soup_home = BeautifulSoup(homepage.content, \"html.parser\")\n",
    "\n",
    "select = soup_home.select_one(\"#dpShares\")\n",
    "options = select.find_all(\"option\")\n",
    "actions = [(opt.text.strip(), opt[\"value\"].strip()) for opt in options if opt[\"value\"].strip()]\n",
    "\n",
    "\n",
    "all_news = []\n",
    "all_communiques = []\n",
    "\n",
    "for nom_action, valeur in actions:\n",
    "    print(f\"🔍 Scraping {nom_action} ({valeur})...\")\n",
    "\n",
    "    url = cot_url + valeur\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    \n",
    "    # 📰 Actualités\n",
    "    actualites_div = soup.find(\"div\", class_=\"home_content\")\n",
    "    if actualites_div:\n",
    "        spans = actualites_div.find_all(\"span\", class_=\"sp1\")\n",
    "        links = actualites_div.find_all(\"a\", class_=\"lks\")\n",
    "        for span, link in zip(spans, links):\n",
    "            all_news.append({\n",
    "                \"Action\": nom_action,\n",
    "                \"Date\": span.text.strip(),\n",
    "                \"Titre\": link.text.strip(),\n",
    "                \"URL\": base_url + link[\"href\"]\n",
    "            })\n",
    "\n",
    "    # 📑 Communiqués (section suivante sur la page)\n",
    "    communiques_section = actualites_div.find_next(\"div\", class_=\"home_content\")\n",
    "    if communiques_section:\n",
    "        spans = communiques_section.find_all(\"span\", class_=\"sp1\")\n",
    "        links = communiques_section.find_all(\"a\", class_=\"lks\")\n",
    "        for span, link in zip(spans, links):\n",
    "            all_communiques.append({\n",
    "                \"Action\": nom_action,\n",
    "                \"Date\": span.text.strip(),\n",
    "                \"Titre\": link.text.strip(),\n",
    "                \"URL\": base_url + link[\"href\"]\n",
    "            })\n",
    "\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👉 Résultats\n",
    "df_news = pd.DataFrame(all_news)\n",
    "df_communiques = pd.DataFrame(all_communiques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75d9250d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données insérées avec succès dans la collection 'actus_communiques'.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Sélection de la base et de la collection\n",
    "db = client[\"sika_finance\"]\n",
    "collection = db[\"actus_communiques\"]\n",
    "\n",
    "# 👉 Création des DataFrames\n",
    "df_news = pd.DataFrame(all_news)\n",
    "df_communiques = pd.DataFrame(all_communiques)\n",
    "\n",
    "# Regrouper par action dans df_news\n",
    "actions_uniques = df_news[\"Action\"].unique()\n",
    "\n",
    "# Parcours de chaque action\n",
    "for action in actions_uniques:\n",
    "    # Filtrer les actualités et communiqués pour cette action\n",
    "    actualites = df_news[df_news[\"Action\"] == action].drop(columns=[\"Action\"]).to_dict(orient=\"records\")\n",
    "    communiques = df_communiques[df_communiques[\"Action\"] == action].drop(columns=[\"Action\"]).to_dict(orient=\"records\")\n",
    "\n",
    "    # Supprimer l'existant si besoin\n",
    "    collection.delete_one({\"action\": action})\n",
    "\n",
    "    # Insertion dans MongoDB\n",
    "    collection.insert_one({\n",
    "        \"action\": action,\n",
    "        \"actualites\": actualites,\n",
    "        \"communiques\": communiques\n",
    "    })\n",
    "\n",
    "print(\"✅ Données insérées avec succès dans la collection 'actus_communiques'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944b694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⌛ Récupération des cotations...\n",
      "✅ AFRICA GLOBAL LOGISTICS mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '460,00'\n",
      "✅ BANK OF AFRICA BENIN mis à jour\n",
      "✅ BANK OF AFRICA BURKINA FASO mis à jour\n",
      "✅ BANK OF AFRICA CI mis à jour\n",
      "✅ BANK OF AFRICA MALI mis à jour\n",
      "✅ BANK OF AFRICA NIGER mis à jour\n",
      "✅ BANK OF AFRICA SENEGAL mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '865,00'\n",
      "✅ BICICI mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '222,91'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '661,74'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '117,46'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '98,55'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '404,35'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '126,51'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '115,18'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '139,29'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '117,67'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '122,03'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '157,18'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '113,20'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '777,90'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '99,60'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '93,97'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '328,58'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '144,66'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '287,19'\n",
      "✅ Capitalisation BRVM mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '610,00'\n",
      "✅ CIE CI mis à jour\n",
      "✅ CORIS BANK INTERNATIONAL BF mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '700,00'\n",
      "✅ ECOBANK CI mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '15,00'\n",
      "✅ FILTISAC CI mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '69,08'\n",
      "Erreur extraction cotations: could not convert string to float: '-'\n",
      "✅ MOVIS CI mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '620,00'\n",
      "✅ NESTLE CI mis à jour\n",
      "✅ NSIA BANQUE mis à jour\n",
      "✅ ONATEL BF mis à jour\n",
      "✅ ORAGROUP TOGO mis à jour\n",
      "✅ ORANGE CI mis à jour\n",
      "✅ PALMCI mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '700,00'\n",
      "✅ SAPH CI mis à jour\n",
      "✅ SERVAIR ABIDJAN CI mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '480,00'\n",
      "✅ SGBCI mis à jour\n",
      "✅ SICABLE CI mis à jour\n",
      "✅ SICOR mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '277,78'\n",
      "✅ SITAB mis à jour\n",
      "✅ SMB CI mis à jour\n",
      "✅ SOCIETE IVOIRIENNE DE BANQUE CI mis à jour\n",
      "✅ SODECI mis à jour\n",
      "✅ SOGB mis à jour\n",
      "✅ SOLIBRA CI mis à jour\n",
      "✅ SONATEL mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '960,00'\n",
      "✅ TOTAL CI mis à jour\n",
      "✅ TOTAL SENEGAL mis à jour\n",
      "✅ TRACTAFRIC MOTORS CI mis à jour\n",
      "✅ UNILEVER CI mis à jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '390,00'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '925,00'\n",
      "⏳ Pause 15 minutes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 96\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# Attendre 15 minutes\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⏳ Pause 15 minutes...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m15\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🕗 Attente de 8h...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Connexion MongoDB\n",
    "db = client[\"sika_finance\"]\n",
    "collection = db[\"cotations\"]\n",
    "\n",
    "def extraire_cotations(soup):\n",
    "    cot1 = soup.find(\"div\", id=\"cot1c\")\n",
    "    if not cot1:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        prix = float(cot1.select_one(\".cot1u\").text.split()[0].replace('\\xa0', '').replace('XOF', '').replace(',', '.'))\n",
    "        variation = cot1.select_one(\".quote_up, .quote_down\").text.strip()\n",
    "        tables = cot1.find_all(\"table\")\n",
    "\n",
    "        values = [td.text.replace('\\xa0', '').strip() for table in tables for td in table.find_all(\"td\")[1::2]]\n",
    "\n",
    "        return {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"prix\": prix,\n",
    "            \"variation\": variation,\n",
    "            \"volume_titres\": float(values[0].replace(' ', '').replace(',', '.')),\n",
    "            \"volume_xof\": float(values[1].replace(' ', '').replace(',', '.')),\n",
    "            \"ouverture\": float(values[2].replace(' ', '').replace(',', '.')),\n",
    "            \"plus_haut\": float(values[3].replace(' ', '').replace(',', '.')),\n",
    "            \"plus_bas\": float(values[4].replace(' ', '').replace(',', '.')),\n",
    "            \"cloture_veille\": float(values[5].replace(' ', '').replace(',', '.')),\n",
    "            \"beta\": float(values[6].replace(',', '.')),\n",
    "            \"rsi\": float(values[7].replace(',', '.')),\n",
    "            \"capital_echange\": values[8],\n",
    "            \"valorisation\": values[9]\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Erreur extraction cotations:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "base_url = \"https://www.sikafinance.com\"\n",
    "cot_url = base_url + \"/marches/cotation_\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# Étape 1 : Récupérer toutes les valeurs du sélecteur\n",
    "homepage = requests.get(cot_url + \"SDSC.ci\", headers=headers)\n",
    "soup_home = BeautifulSoup(homepage.content, \"html.parser\")\n",
    "\n",
    "select = soup_home.select_one(\"#dpShares\")\n",
    "options = select.find_all(\"option\")\n",
    "actions = [(opt.text.strip(), opt[\"value\"].strip()) for opt in options if opt[\"value\"].strip()]\n",
    "\n",
    "# Définir l'heure d'ouverture et de fermeture du marché\n",
    "start = datetime.now().replace(hour=8, minute=0, second=0, microsecond=0)\n",
    "end = datetime.now().replace(hour=18, minute=30, second=0, microsecond=0)\n",
    "\n",
    "# Liste pour stocker les cotations pendant la journée\n",
    "all_cotations = []\n",
    "\n",
    "while datetime.now() < end:\n",
    "    if datetime.now() >= start:\n",
    "        print(\"⌛ Récupération des cotations...\")\n",
    "\n",
    "        # Liste temporaire pour les cotations de cette période\n",
    "        cotations_period = []\n",
    "\n",
    "        for nom_action, valeur in actions:\n",
    "            try:\n",
    "                url = cot_url + valeur\n",
    "                response = requests.get(url, headers=headers)\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "                cotation = extraire_cotations(soup)\n",
    "                if cotation:\n",
    "                    cotations_period.append({\n",
    "                        \"action\": nom_action,\n",
    "                        **cotation  # Ajoute les cotations extraites à l'entrée\n",
    "                    })\n",
    "                    print(f\"✅ {nom_action} mis à jour\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Erreur lors de la mise à jour de {nom_action}: {e}\")\n",
    "\n",
    "        if cotations_period:\n",
    "            # Ajouter les cotations de la période dans le DataFrame\n",
    "            df = pd.DataFrame(cotations_period)\n",
    "            all_cotations.append(df)\n",
    "        \n",
    "        # Attendre 15 minutes\n",
    "        print(\"⏳ Pause 15 minutes...\")\n",
    "#     \"time.sleep(15 * 60)\n",
    "    else:\n",
    "        print(\"🕗 Attente de 8h...\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "130762e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Toutes les cotations ont été insérées dans la base de données.\n"
     ]
    }
   ],
   "source": [
    "# Une fois la période terminée, concaténer les DataFrames collectés\n",
    "if all_cotations:\n",
    "    final_df = pd.concat(all_cotations, ignore_index=True)\n",
    "\n",
    "    # Insérer dans la base de données MongoDB\n",
    "    for _, row in final_df.iterrows():\n",
    "        collection.update_one(\n",
    "            {\"action\": row[\"action\"]},\n",
    "            {\"$push\": {\"cotations\": row.to_dict()}},  # Ajouter chaque cotation à l'action correspondante\n",
    "            upsert=True\n",
    "        )\n",
    "    print(\"✅ Toutes les cotations ont été insérées dans la base de données.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6766c4da",
   "metadata": {},
   "source": [
    "# ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c621a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Récupération des données de 01/01/2025 à 20/04/2025\n",
      "\n",
      "🔍 Traitement de AFRICA GLOBAL LOGISTICS (SDSC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour AFRICA GLOBAL LOGISTICS\n",
      "\n",
      "🔍 Traitement de AIR LIQUIDE CI (SIVC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour AIR LIQUIDE CI\n",
      "\n",
      "🔍 Traitement de BANK OF AFRICA BENIN (BOAB.bj)...\n",
      "✅ 63 nouvelles lignes insérées pour BANK OF AFRICA BENIN\n",
      "\n",
      "🔍 Traitement de BANK OF AFRICA BURKINA FASO (BOABF.bf)...\n",
      "✅ 63 nouvelles lignes insérées pour BANK OF AFRICA BURKINA FASO\n",
      "\n",
      "🔍 Traitement de BANK OF AFRICA CI (BOAC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour BANK OF AFRICA CI\n",
      "\n",
      "🔍 Traitement de BANK OF AFRICA MALI (BOAM.ml)...\n",
      "✅ 63 nouvelles lignes insérées pour BANK OF AFRICA MALI\n",
      "\n",
      "🔍 Traitement de BANK OF AFRICA NIGER (BOAN.ne)...\n",
      "✅ 63 nouvelles lignes insérées pour BANK OF AFRICA NIGER\n",
      "\n",
      "🔍 Traitement de BANK OF AFRICA SENEGAL (BOAS.sn)...\n",
      "✅ 63 nouvelles lignes insérées pour BANK OF AFRICA SENEGAL\n",
      "\n",
      "🔍 Traitement de BANQUE INTERNATIONALE POUR LE COMMERCE DU BENIN (BICB.bj)...\n",
      "ℹ️ Aucune nouvelle donnée à insérer pour BANQUE INTERNATIONALE POUR LE COMMERCE DU BENIN\n",
      "\n",
      "🔍 Traitement de BERNABE (BNBC.ci)...\n",
      "✅ 62 nouvelles lignes insérées pour BERNABE\n",
      "\n",
      "🔍 Traitement de BICICI (BICC.ci)...\n",
      "✅ 61 nouvelles lignes insérées pour BICICI\n",
      "\n",
      "🔍 Traitement de BRVM - AGRICULTURE (BRVMAG)...\n",
      "⚠️ Erreur lors du traitement de BRVM - AGRICULTURE: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - AUTRES SECTEURS (BRVMAS)...\n",
      "⚠️ Erreur lors du traitement de BRVM - AUTRES SECTEURS: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - CONSOMMATION DE BASE (BRVM-CB)...\n",
      "⚠️ Erreur lors du traitement de BRVM - CONSOMMATION DE BASE: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - CONSOMMATION DISCRETIONNAIRE (BRVM-CD)...\n",
      "⚠️ Erreur lors du traitement de BRVM - CONSOMMATION DISCRETIONNAIRE: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - DISTRIBUTION (BRVMDI)...\n",
      "⚠️ Erreur lors du traitement de BRVM - DISTRIBUTION: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - ENERGIE (BRVM-EN)...\n",
      "⚠️ Erreur lors du traitement de BRVM - ENERGIE: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - FINANCE (BRVMFI)...\n",
      "⚠️ Erreur lors du traitement de BRVM - FINANCE: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - INDUSTRIE (BRVMIN)...\n",
      "⚠️ Erreur lors du traitement de BRVM - INDUSTRIE: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - INDUSTRIELS (BRVM-IN)...\n",
      "⚠️ Erreur lors du traitement de BRVM - INDUSTRIELS: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - PRESTIGE (BRVMPR)...\n",
      "⚠️ Erreur lors du traitement de BRVM - PRESTIGE: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - PRINCIPAL (BRVMPA)...\n",
      "⚠️ Erreur lors du traitement de BRVM - PRINCIPAL: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - SERVICES FINANCIERS (BRVM-SF)...\n",
      "⚠️ Erreur lors du traitement de BRVM - SERVICES FINANCIERS: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - SERVICES PUBLICS (BRVMSP)...\n",
      "⚠️ Erreur lors du traitement de BRVM - SERVICES PUBLICS: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - SERVICES PUBLICS (BRVM-SP)...\n",
      "⚠️ Erreur lors du traitement de BRVM - SERVICES PUBLICS: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - TELECOMMUNICATIONS (BRVM-TEL)...\n",
      "⚠️ Erreur lors du traitement de BRVM - TELECOMMUNICATIONS: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM - TRANSPORT (BRVMTR)...\n",
      "⚠️ Erreur lors du traitement de BRVM - TRANSPORT: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM 30 (BRVM30)...\n",
      "⚠️ Erreur lors du traitement de BRVM 30: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de BRVM COMPOSITE (BRVMC)...\n",
      "⚠️ Erreur lors du traitement de BRVM COMPOSITE: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de Capitalisation BRVM (CAPIBRVM)...\n",
      "⚠️ Erreur lors du traitement de Capitalisation BRVM: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de CFAO CI (CFAC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour CFAO CI\n",
      "\n",
      "🔍 Traitement de CIE CI (CIEC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour CIE CI\n",
      "\n",
      "🔍 Traitement de CORIS BANK INTERNATIONAL BF (CBIBF.bf)...\n",
      "✅ 63 nouvelles lignes insérées pour CORIS BANK INTERNATIONAL BF\n",
      "\n",
      "🔍 Traitement de CROWN SIEM (SEMC.ci)...\n",
      "ℹ️ Aucune nouvelle donnée à insérer pour CROWN SIEM\n",
      "\n",
      "🔍 Traitement de ECOBANK CI (ECOC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour ECOBANK CI\n",
      "\n",
      "🔍 Traitement de ETI TG (ETIT.tg)...\n",
      "✅ 63 nouvelles lignes insérées pour ETI TG\n",
      "\n",
      "🔍 Traitement de FILTISAC CI (FTSC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour FILTISAC CI\n",
      "\n",
      "🔍 Traitement de INDICE SIKAFINANCE (SIKAIDX)...\n",
      "⚠️ Erreur lors du traitement de INDICE SIKAFINANCE: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de LOTERIE NATIONALE DU BENIN (LNBB.bj)...\n",
      "✅ 63 nouvelles lignes insérées pour LOTERIE NATIONALE DU BENIN\n",
      "\n",
      "🔍 Traitement de MOVIS CI (SVOC.ci)...\n",
      "ℹ️ Aucune nouvelle donnée à insérer pour MOVIS CI\n",
      "\n",
      "🔍 Traitement de NEI CEDA CI (NEIC.ci)...\n",
      "✅ 60 nouvelles lignes insérées pour NEI CEDA CI\n",
      "\n",
      "🔍 Traitement de NESTLE CI (NTLC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour NESTLE CI\n",
      "\n",
      "🔍 Traitement de NSIA BANQUE (NSBC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour NSIA BANQUE\n",
      "\n",
      "🔍 Traitement de ONATEL BF (ONTBF.bf)...\n",
      "✅ 63 nouvelles lignes insérées pour ONATEL BF\n",
      "\n",
      "🔍 Traitement de ORAGROUP TOGO (ORGT.tg)...\n",
      "✅ 62 nouvelles lignes insérées pour ORAGROUP TOGO\n",
      "\n",
      "🔍 Traitement de ORANGE CI (ORAC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour ORANGE CI\n",
      "\n",
      "🔍 Traitement de PALMCI (PALC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour PALMCI\n",
      "\n",
      "🔍 Traitement de SAFCA CI (SAFC.ci)...\n",
      "✅ 52 nouvelles lignes insérées pour SAFCA CI\n",
      "\n",
      "🔍 Traitement de SAPH CI (SPHC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour SAPH CI\n",
      "\n",
      "🔍 Traitement de SERVAIR ABIDJAN CI (ABJC.ci)...\n",
      "✅ 62 nouvelles lignes insérées pour SERVAIR ABIDJAN CI\n",
      "\n",
      "🔍 Traitement de SETAO CI (STAC.ci)...\n",
      "✅ 59 nouvelles lignes insérées pour SETAO CI\n",
      "\n",
      "🔍 Traitement de SGBCI (SGBC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour SGBCI\n",
      "\n",
      "🔍 Traitement de SICABLE CI (CABC.ci)...\n",
      "✅ 62 nouvelles lignes insérées pour SICABLE CI\n",
      "\n",
      "🔍 Traitement de SICOR (SICC.ci)...\n",
      "✅ 46 nouvelles lignes insérées pour SICOR\n",
      "\n",
      "🔍 Traitement de SIKA TOTAL RETURN (SIKATR)...\n",
      "⚠️ Erreur lors du traitement de SIKA TOTAL RETURN: could not convert string to float: '-'\n",
      "\n",
      "🔍 Traitement de SITAB (STBC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour SITAB\n",
      "\n",
      "🔍 Traitement de SMB CI (SMBC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour SMB CI\n",
      "\n",
      "🔍 Traitement de SOCIETE IVOIRIENNE DE BANQUE CI (SIBC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour SOCIETE IVOIRIENNE DE BANQUE CI\n",
      "\n",
      "🔍 Traitement de SODECI (SDCC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour SODECI\n",
      "\n",
      "🔍 Traitement de SOGB (SOGC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour SOGB\n",
      "\n",
      "🔍 Traitement de SOLIBRA CI (SLBC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour SOLIBRA CI\n",
      "\n",
      "🔍 Traitement de SONATEL (SNTS.sn)...\n",
      "✅ 63 nouvelles lignes insérées pour SONATEL\n",
      "\n",
      "🔍 Traitement de SUCRIVOIRE (SCRC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour SUCRIVOIRE\n",
      "\n",
      "🔍 Traitement de TOTAL CI (TTLC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour TOTAL CI\n",
      "\n",
      "🔍 Traitement de TOTAL SENEGAL (TTLS.sn)...\n",
      "✅ 63 nouvelles lignes insérées pour TOTAL SENEGAL\n",
      "\n",
      "🔍 Traitement de TRACTAFRIC MOTORS CI (PRSC.ci)...\n",
      "✅ 60 nouvelles lignes insérées pour TRACTAFRIC MOTORS CI\n",
      "\n",
      "🔍 Traitement de UNILEVER CI (UNLC.ci)...\n",
      "✅ 37 nouvelles lignes insérées pour UNILEVER CI\n",
      "\n",
      "🔍 Traitement de UNIWAX CI (UNXC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour UNIWAX CI\n",
      "\n",
      "🔍 Traitement de VIVO ENERGY CI (SHEC.ci)...\n",
      "✅ 63 nouvelles lignes insérées pour VIVO ENERGY CI\n",
      "🚀 Scraping terminé et données mises à jour.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Connexion MongoDB\n",
    "client = MongoClient(os.getenv(\"MONGO_URI\"))\n",
    "db = client[\"sika_finance\"]\n",
    "collection = db[\"historique_actions\"]\n",
    "\n",
    "def get_last_record_date():\n",
    "    last_record = collection.find_one(sort=[(\"historique.Date\", -1)])\n",
    "    if last_record and \"historique\" in last_record and last_record[\"historique\"]:\n",
    "        last_date_str = last_record[\"historique\"][-1][\"Date\"]\n",
    "        try:\n",
    "            return datetime.strptime(last_date_str, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(f\"Erreur de format pour la date: {last_date_str}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Calcul des dates pour la récupération des données\n",
    "last_date = get_last_record_date()\n",
    "if last_date:\n",
    "    date_from = (last_date + timedelta(days=1))\n",
    "else:\n",
    "    date_from = datetime.strptime(\"01/01/2025\", \"%d/%m/%Y\")\n",
    "\n",
    "date_to = datetime.now()\n",
    "\n",
    "print(f\"📅 Récupération des données de {date_from.strftime('%d/%m/%Y')} à {date_to.strftime('%d/%m/%Y')}\")\n",
    "\n",
    "# Configuration Selenium\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "driver.get(\"https://www.sikafinance.com/marches/historiques/SDSC.ci\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Liste des actions\n",
    "select_element = wait.until(EC.presence_of_element_located((By.ID, \"dpShares\")))\n",
    "select_html = Select(select_element)\n",
    "options = [(opt.text.strip(), opt.get_attribute(\"value\").strip()) for opt in select_html.options if opt.get_attribute(\"value\").strip()]\n",
    "\n",
    "for nom_action, valeur in options:\n",
    "    print(f\"\\n🔍 Traitement de {nom_action} ({valeur})...\")\n",
    "\n",
    "    driver.get(f\"https://www.sikafinance.com/marches/historiques/{valeur}\")\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        datefrom_input = wait.until(EC.presence_of_element_located((By.ID, \"datefrom\")))\n",
    "        dateto_input = driver.find_element(By.ID, \"dateto\")\n",
    "\n",
    "        datefrom_input.clear()\n",
    "        datefrom_input.send_keys(date_from.strftime(\"%d/%m/%Y\"))\n",
    "        dateto_input.clear()\n",
    "        dateto_input.send_keys(date_to.strftime(\"%d/%m/%Y\"))\n",
    "\n",
    "        driver.find_element(By.ID, \"btnChange\").click()\n",
    "        time.sleep(5)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        table = soup.find(\"table\", id=\"tblhistos\")\n",
    "\n",
    "        if table:\n",
    "            headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "            rows = [[td.text.strip() for td in tr.find_all(\"td\")] for tr in table.find_all(\"tr\")[1:] if tr.find_all(\"td\")]\n",
    "            df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "            # Nettoyage + conversions\n",
    "            colonnes_numeriques = [\"Clôture\", \"Plus bas\", \"Plus haut\", \"Ouverture\", \"Volume Titres\", \"Volume FCFA\", \"Variation %\"]\n",
    "            for col in colonnes_numeriques:\n",
    "                df[col] = df[col].str.replace(\",\", \"\").str.replace(\"%\", \"\").str.replace(\"\\xa0\", \"\").astype(float)\n",
    "\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\")\n",
    "            df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "            df[\"Action\"] = nom_action\n",
    "\n",
    "            # Extraction des dates déjà présentes\n",
    "            record = collection.find_one({\"action\": nom_action}, {\"historique.Date\": 1})\n",
    "            dates_existantes = set()\n",
    "            if record and \"historique\" in record:\n",
    "                dates_existantes = set(h[\"Date\"] for h in record[\"historique\"])\n",
    "\n",
    "            # Construction des nouveaux enregistrements\n",
    "            new_records = []\n",
    "            for _, row in df.iterrows():\n",
    "                date_iso = row[\"Date\"].strftime(\"%Y-%m-%d\")\n",
    "                if date_iso not in dates_existantes:\n",
    "                    new_records.append({\n",
    "                        \"Date\": date_iso,\n",
    "                        \"Clôture\": row[\"Clôture\"],\n",
    "                        \"Plus bas\": row[\"Plus bas\"],\n",
    "                        \"Plus haut\": row[\"Plus haut\"],\n",
    "                        \"Ouverture\": row[\"Ouverture\"],\n",
    "                        \"Volume Titres\": row[\"Volume Titres\"],\n",
    "                        \"Volume FCFA\": row[\"Volume FCFA\"],\n",
    "                        \"Variation %\": row[\"Variation %\"],\n",
    "                        \"Action\": nom_action\n",
    "                    })\n",
    "\n",
    "            if new_records:\n",
    "                collection.update_one(\n",
    "                    {\"action\": nom_action},\n",
    "                    {\"$push\": {\"historique\": {\"$each\": new_records}}},\n",
    "                    upsert=True\n",
    "                )\n",
    "                print(f\"✅ {len(new_records)} nouvelles lignes insérées pour {nom_action}\")\n",
    "            else:\n",
    "                print(f\"ℹ️ Aucune nouvelle donnée à insérer pour {nom_action}\")\n",
    "        else:\n",
    "            print(f\"❌ Aucun tableau trouvé pour {nom_action}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Erreur lors du traitement de {nom_action}: {e}\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "driver.quit()\n",
    "print(\"🚀 Scraping terminé et données mises à jour.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
