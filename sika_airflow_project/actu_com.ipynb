{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248e9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connexion au cluster MongoDB Atlas\n",
    "client = MongoClient(\"mongodb+srv://amedbah2000:NQerjnFDI1xA8Dc1@cluster0.vbt1opf.mongodb.net/?retryWrites=true&w=majority\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5d052",
   "metadata": {},
   "source": [
    "## Actu et communiqu√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scraping AFRICA GLOBAL¬†LOGISTICS (SDSC.ci)...\n",
      "üîç Scraping AIR LIQUIDE CI (SIVC.ci)...\n",
      "üîç Scraping BANK OF AFRICA BENIN (BOAB.bj)...\n",
      "üîç Scraping BANK OF AFRICA BURKINA FASO (BOABF.bf)...\n",
      "üîç Scraping BANK OF AFRICA CI (BOAC.ci)...\n",
      "üîç Scraping BANK OF AFRICA MALI (BOAM.ml)...\n",
      "üîç Scraping BANK OF AFRICA NIGER (BOAN.ne)...\n",
      "üîç Scraping BANK OF AFRICA SENEGAL (BOAS.sn)...\n",
      "üîç Scraping BERNABE (BNBC.ci)...\n",
      "üîç Scraping BICICI (BICC.ci)...\n",
      "üîç Scraping BRVM - AGRICULTURE (BRVMAG)...\n",
      "üîç Scraping BRVM - AUTRES SECTEURS (BRVMAS)...\n",
      "üîç Scraping BRVM - CONSOMMATION DE BASE (BRVM-CB)...\n",
      "üîç Scraping BRVM - CONSOMMATION DISCRETIONNAIRE (BRVM-CD)...\n",
      "üîç Scraping BRVM - DISTRIBUTION (BRVMDI)...\n",
      "üîç Scraping BRVM - ENERGIE (BRVM-EN)...\n",
      "üîç Scraping BRVM - FINANCE (BRVMFI)...\n",
      "üîç Scraping BRVM - INDUSTRIE (BRVMIN)...\n",
      "üîç Scraping BRVM - INDUSTRIELS (BRVM-IN)...\n",
      "üîç Scraping BRVM - PRESTIGE (BRVMPR)...\n",
      "üîç Scraping BRVM - PRINCIPAL (BRVMPA)...\n",
      "üîç Scraping BRVM - SERVICES FINANCIERS (BRVM-SF)...\n",
      "üîç Scraping BRVM - SERVICES PUBLICS (BRVMSP)...\n",
      "üîç Scraping BRVM - SERVICES PUBLICS (BRVM-SP)...\n",
      "üîç Scraping BRVM - TELECOMMUNICATIONS (BRVM-TEL)...\n",
      "üîç Scraping BRVM - TRANSPORT (BRVMTR)...\n",
      "üîç Scraping BRVM 30 (BRVM30)...\n",
      "üîç Scraping BRVM COMPOSITE (BRVMC)...\n",
      "üîç Scraping Capitalisation BRVM (CAPIBRVM)...\n",
      "üîç Scraping CFAO CI (CFAC.ci)...\n",
      "üîç Scraping CIE CI (CIEC.ci)...\n",
      "üîç Scraping CORIS BANK INTERNATIONAL BF (CBIBF.bf)...\n",
      "üîç Scraping CROWN SIEM (SEMC.ci)...\n",
      "üîç Scraping ECOBANK CI (ECOC.ci)...\n",
      "üîç Scraping ETI TG (ETIT.tg)...\n",
      "üîç Scraping FILTISAC CI (FTSC.ci)...\n",
      "üîç Scraping INDICE SIKAFINANCE (SIKAIDX)...\n",
      "üîç Scraping LOTERIE NATIONALE DU BENIN (LNBB.bj)...\n",
      "üîç Scraping MOVIS CI (SVOC.ci)...\n",
      "üîç Scraping NEI CEDA CI (NEIC.ci)...\n",
      "üîç Scraping NESTLE CI (NTLC.ci)...\n",
      "üîç Scraping NSIA BANQUE (NSBC.ci)...\n",
      "üîç Scraping ONATEL BF (ONTBF.bf)...\n",
      "üîç Scraping ORAGROUP TOGO (ORGT.tg)...\n",
      "üîç Scraping ORANGE CI (ORAC.ci)...\n",
      "üîç Scraping PALMCI (PALC.ci)...\n",
      "üîç Scraping SAFCA CI (SAFC.ci)...\n",
      "üîç Scraping SAPH CI (SPHC.ci)...\n",
      "üîç Scraping SERVAIR ABIDJAN CI (ABJC.ci)...\n",
      "üîç Scraping SETAO CI (STAC.ci)...\n",
      "üîç Scraping SGBCI (SGBC.ci)...\n",
      "üîç Scraping SICABLE CI (CABC.ci)...\n",
      "üîç Scraping SICOR (SICC.ci)...\n",
      "üîç Scraping SIKA TOTAL RETURN (SIKATR)...\n",
      "üîç Scraping SITAB (STBC.ci)...\n",
      "üîç Scraping SMB CI (SMBC.ci)...\n",
      "üîç Scraping SOCIETE IVOIRIENNE DE BANQUE CI (SIBC.ci)...\n",
      "üîç Scraping SODECI (SDCC.ci)...\n",
      "üîç Scraping SOGB (SOGC.ci)...\n",
      "üîç Scraping SOLIBRA CI (SLBC.ci)...\n",
      "üîç Scraping SONATEL (SNTS.sn)...\n",
      "üîç Scraping SUCRIVOIRE (SCRC.ci)...\n",
      "üîç Scraping TOTAL CI (TTLC.ci)...\n",
      "üîç Scraping TOTAL SENEGAL (TTLS.sn)...\n",
      "üîç Scraping TRACTAFRIC MOTORS CI (PRSC.ci)...\n",
      "üîç Scraping UNILEVER CI (UNLC.ci)...\n",
      "üîç Scraping UNIWAX CI (UNXC.ci)...\n",
      "üîç Scraping VIVO ENERGY CI (SHEC.ci)...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "base_url = \"https://www.sikafinance.com\"\n",
    "cot_url = base_url + \"/marches/cotation_\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# √âtape 1 : R√©cup√©rer toutes les valeurs du s√©lecteur\n",
    "homepage = requests.get(cot_url + \"SDSC.ci\", headers=headers)\n",
    "soup_home = BeautifulSoup(homepage.content, \"html.parser\")\n",
    "\n",
    "select = soup_home.select_one(\"#dpShares\")\n",
    "options = select.find_all(\"option\")\n",
    "actions = [(opt.text.strip(), opt[\"value\"].strip()) for opt in options if opt[\"value\"].strip()]\n",
    "\n",
    "\n",
    "all_news = []\n",
    "all_communiques = []\n",
    "\n",
    "for nom_action, valeur in actions:\n",
    "    print(f\"üîç Scraping {nom_action} ({valeur})...\")\n",
    "\n",
    "    url = cot_url + valeur\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    \n",
    "    # üì∞ Actualit√©s\n",
    "    actualites_div = soup.find(\"div\", class_=\"home_content\")\n",
    "    if actualites_div:\n",
    "        spans = actualites_div.find_all(\"span\", class_=\"sp1\")\n",
    "        links = actualites_div.find_all(\"a\", class_=\"lks\")\n",
    "        for span, link in zip(spans, links):\n",
    "            all_news.append({\n",
    "                \"Action\": nom_action,\n",
    "                \"Date\": span.text.strip(),\n",
    "                \"Titre\": link.text.strip(),\n",
    "                \"URL\": base_url + link[\"href\"]\n",
    "            })\n",
    "\n",
    "    # üìë Communiqu√©s (section suivante sur la page)\n",
    "    communiques_section = actualites_div.find_next(\"div\", class_=\"home_content\")\n",
    "    if communiques_section:\n",
    "        spans = communiques_section.find_all(\"span\", class_=\"sp1\")\n",
    "        links = communiques_section.find_all(\"a\", class_=\"lks\")\n",
    "        for span, link in zip(spans, links):\n",
    "            all_communiques.append({\n",
    "                \"Action\": nom_action,\n",
    "                \"Date\": span.text.strip(),\n",
    "                \"Titre\": link.text.strip(),\n",
    "                \"URL\": base_url + link[\"href\"]\n",
    "            })\n",
    "\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üëâ R√©sultats\n",
    "df_news = pd.DataFrame(all_news)\n",
    "df_communiques = pd.DataFrame(all_communiques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75d9250d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es ins√©r√©es avec succ√®s dans la collection 'actus_communiques'.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# S√©lection de la base et de la collection\n",
    "db = client[\"sika_finance\"]\n",
    "collection = db[\"actus_communiques\"]\n",
    "\n",
    "# üëâ Cr√©ation des DataFrames\n",
    "df_news = pd.DataFrame(all_news)\n",
    "df_communiques = pd.DataFrame(all_communiques)\n",
    "\n",
    "# Regrouper par action dans df_news\n",
    "actions_uniques = df_news[\"Action\"].unique()\n",
    "\n",
    "# Parcours de chaque action\n",
    "for action in actions_uniques:\n",
    "    # Filtrer les actualit√©s et communiqu√©s pour cette action\n",
    "    actualites = df_news[df_news[\"Action\"] == action].drop(columns=[\"Action\"]).to_dict(orient=\"records\")\n",
    "    communiques = df_communiques[df_communiques[\"Action\"] == action].drop(columns=[\"Action\"]).to_dict(orient=\"records\")\n",
    "\n",
    "    # Supprimer l'existant si besoin\n",
    "    collection.delete_one({\"action\": action})\n",
    "\n",
    "    # Insertion dans MongoDB\n",
    "    collection.insert_one({\n",
    "        \"action\": action,\n",
    "        \"actualites\": actualites,\n",
    "        \"communiques\": communiques\n",
    "    })\n",
    "\n",
    "print(\"‚úÖ Donn√©es ins√©r√©es avec succ√®s dans la collection 'actus_communiques'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944b694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚åõ R√©cup√©ration des cotations...\n",
      "‚úÖ AFRICA GLOBAL¬†LOGISTICS mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '460,00'\n",
      "‚úÖ BANK OF AFRICA BENIN mis √† jour\n",
      "‚úÖ BANK OF AFRICA BURKINA FASO mis √† jour\n",
      "‚úÖ BANK OF AFRICA CI mis √† jour\n",
      "‚úÖ BANK OF AFRICA MALI mis √† jour\n",
      "‚úÖ BANK OF AFRICA NIGER mis √† jour\n",
      "‚úÖ BANK OF AFRICA SENEGAL mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '865,00'\n",
      "‚úÖ BICICI mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '222,91'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '661,74'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '117,46'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '98,55'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '404,35'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '126,51'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '115,18'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '139,29'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '117,67'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '122,03'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '157,18'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '113,20'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '777,90'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '99,60'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '93,97'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '328,58'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '144,66'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '287,19'\n",
      "‚úÖ Capitalisation BRVM mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '610,00'\n",
      "‚úÖ CIE CI mis √† jour\n",
      "‚úÖ CORIS BANK INTERNATIONAL BF mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '700,00'\n",
      "‚úÖ ECOBANK CI mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '15,00'\n",
      "‚úÖ FILTISAC CI mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '69,08'\n",
      "Erreur extraction cotations: could not convert string to float: '-'\n",
      "‚úÖ MOVIS CI mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '620,00'\n",
      "‚úÖ NESTLE CI mis √† jour\n",
      "‚úÖ NSIA BANQUE mis √† jour\n",
      "‚úÖ ONATEL BF mis √† jour\n",
      "‚úÖ ORAGROUP TOGO mis √† jour\n",
      "‚úÖ ORANGE CI mis √† jour\n",
      "‚úÖ PALMCI mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '700,00'\n",
      "‚úÖ SAPH CI mis √† jour\n",
      "‚úÖ SERVAIR ABIDJAN CI mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '480,00'\n",
      "‚úÖ SGBCI mis √† jour\n",
      "‚úÖ SICABLE CI mis √† jour\n",
      "‚úÖ SICOR mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '277,78'\n",
      "‚úÖ SITAB mis √† jour\n",
      "‚úÖ SMB CI mis √† jour\n",
      "‚úÖ SOCIETE IVOIRIENNE DE BANQUE CI mis √† jour\n",
      "‚úÖ SODECI mis √† jour\n",
      "‚úÖ SOGB mis √† jour\n",
      "‚úÖ SOLIBRA CI mis √† jour\n",
      "‚úÖ SONATEL mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '960,00'\n",
      "‚úÖ TOTAL CI mis √† jour\n",
      "‚úÖ TOTAL SENEGAL mis √† jour\n",
      "‚úÖ TRACTAFRIC MOTORS CI mis √† jour\n",
      "‚úÖ UNILEVER CI mis √† jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '390,00'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '925,00'\n",
      "‚è≥ Pause 15 minutes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 96\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# Attendre 15 minutes\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚è≥ Pause 15 minutes...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m15\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müïó Attente de 8h...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Connexion MongoDB\n",
    "db = client[\"sika_finance\"]\n",
    "collection = db[\"cotations\"]\n",
    "\n",
    "def extraire_cotations(soup):\n",
    "    cot1 = soup.find(\"div\", id=\"cot1c\")\n",
    "    if not cot1:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        prix = float(cot1.select_one(\".cot1u\").text.split()[0].replace('\\xa0', '').replace('XOF', '').replace(',', '.'))\n",
    "        variation = cot1.select_one(\".quote_up, .quote_down\").text.strip()\n",
    "        tables = cot1.find_all(\"table\")\n",
    "\n",
    "        values = [td.text.replace('\\xa0', '').strip() for table in tables for td in table.find_all(\"td\")[1::2]]\n",
    "\n",
    "        return {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"prix\": prix,\n",
    "            \"variation\": variation,\n",
    "            \"volume_titres\": float(values[0].replace(' ', '').replace(',', '.')),\n",
    "            \"volume_xof\": float(values[1].replace(' ', '').replace(',', '.')),\n",
    "            \"ouverture\": float(values[2].replace(' ', '').replace(',', '.')),\n",
    "            \"plus_haut\": float(values[3].replace(' ', '').replace(',', '.')),\n",
    "            \"plus_bas\": float(values[4].replace(' ', '').replace(',', '.')),\n",
    "            \"cloture_veille\": float(values[5].replace(' ', '').replace(',', '.')),\n",
    "            \"beta\": float(values[6].replace(',', '.')),\n",
    "            \"rsi\": float(values[7].replace(',', '.')),\n",
    "            \"capital_echange\": values[8],\n",
    "            \"valorisation\": values[9]\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Erreur extraction cotations:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "base_url = \"https://www.sikafinance.com\"\n",
    "cot_url = base_url + \"/marches/cotation_\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# √âtape 1 : R√©cup√©rer toutes les valeurs du s√©lecteur\n",
    "homepage = requests.get(cot_url + \"SDSC.ci\", headers=headers)\n",
    "soup_home = BeautifulSoup(homepage.content, \"html.parser\")\n",
    "\n",
    "select = soup_home.select_one(\"#dpShares\")\n",
    "options = select.find_all(\"option\")\n",
    "actions = [(opt.text.strip(), opt[\"value\"].strip()) for opt in options if opt[\"value\"].strip()]\n",
    "\n",
    "# D√©finir l'heure d'ouverture et de fermeture du march√©\n",
    "start = datetime.now().replace(hour=8, minute=0, second=0, microsecond=0)\n",
    "end = datetime.now().replace(hour=18, minute=30, second=0, microsecond=0)\n",
    "\n",
    "# Liste pour stocker les cotations pendant la journ√©e\n",
    "all_cotations = []\n",
    "\n",
    "while datetime.now() < end:\n",
    "    if datetime.now() >= start:\n",
    "        print(\"‚åõ R√©cup√©ration des cotations...\")\n",
    "\n",
    "        # Liste temporaire pour les cotations de cette p√©riode\n",
    "        cotations_period = []\n",
    "\n",
    "        for nom_action, valeur in actions:\n",
    "            try:\n",
    "                url = cot_url + valeur\n",
    "                response = requests.get(url, headers=headers)\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "                cotation = extraire_cotations(soup)\n",
    "                if cotation:\n",
    "                    cotations_period.append({\n",
    "                        \"action\": nom_action,\n",
    "                        **cotation  # Ajoute les cotations extraites √† l'entr√©e\n",
    "                    })\n",
    "                    print(f\"‚úÖ {nom_action} mis √† jour\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur lors de la mise √† jour de {nom_action}: {e}\")\n",
    "\n",
    "        if cotations_period:\n",
    "            # Ajouter les cotations de la p√©riode dans le DataFrame\n",
    "            df = pd.DataFrame(cotations_period)\n",
    "            all_cotations.append(df)\n",
    "        \n",
    "        # Attendre 15 minutes\n",
    "        print(\"‚è≥ Pause 15 minutes...\")\n",
    "#     \"time.sleep(15 * 60)\n",
    "    else:\n",
    "        print(\"üïó Attente de 8h...\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "130762e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Toutes les cotations ont √©t√© ins√©r√©es dans la base de donn√©es.\n"
     ]
    }
   ],
   "source": [
    "# Une fois la p√©riode termin√©e, concat√©ner les DataFrames collect√©s\n",
    "if all_cotations:\n",
    "    final_df = pd.concat(all_cotations, ignore_index=True)\n",
    "\n",
    "    # Ins√©rer dans la base de donn√©es MongoDB\n",
    "    for _, row in final_df.iterrows():\n",
    "        collection.update_one(\n",
    "            {\"action\": row[\"action\"]},\n",
    "            {\"$push\": {\"cotations\": row.to_dict()}},  # Ajouter chaque cotation √† l'action correspondante\n",
    "            upsert=True\n",
    "        )\n",
    "    print(\"‚úÖ Toutes les cotations ont √©t√© ins√©r√©es dans la base de donn√©es.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
