{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a6f530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ClÃ´ture</th>\n",
       "      <th>Plus bas</th>\n",
       "      <th>Plus haut</th>\n",
       "      <th>Ouverture</th>\n",
       "      <th>Volume Titres</th>\n",
       "      <th>Volume FCFA</th>\n",
       "      <th>Variation %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/04/2025</td>\n",
       "      <td>1Â 310</td>\n",
       "      <td>1Â 305</td>\n",
       "      <td>1Â 310</td>\n",
       "      <td>1Â 305</td>\n",
       "      <td>4Â 579</td>\n",
       "      <td>5Â 998Â 490</td>\n",
       "      <td>0,38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/04/2025</td>\n",
       "      <td>1Â 305</td>\n",
       "      <td>1Â 305</td>\n",
       "      <td>1Â 325</td>\n",
       "      <td>1Â 325</td>\n",
       "      <td>1Â 401</td>\n",
       "      <td>1Â 828Â 305</td>\n",
       "      <td>-1,51%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/04/2025</td>\n",
       "      <td>1Â 325</td>\n",
       "      <td>1Â 325</td>\n",
       "      <td>1Â 335</td>\n",
       "      <td>1Â 335</td>\n",
       "      <td>24Â 199</td>\n",
       "      <td>32Â 063Â 675</td>\n",
       "      <td>-1,85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/04/2025</td>\n",
       "      <td>1Â 350</td>\n",
       "      <td>1Â 350</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>599</td>\n",
       "      <td>808Â 650</td>\n",
       "      <td>-1,46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07/04/2025</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>1Â 925</td>\n",
       "      <td>2Â 637Â 250</td>\n",
       "      <td>0,00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>04/04/2025</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>1Â 370</td>\n",
       "      <td>2Â 174</td>\n",
       "      <td>2Â 978Â 380</td>\n",
       "      <td>-0,72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03/04/2025</td>\n",
       "      <td>1Â 380</td>\n",
       "      <td>1Â 380</td>\n",
       "      <td>1Â 380</td>\n",
       "      <td>1Â 380</td>\n",
       "      <td>3Â 353</td>\n",
       "      <td>4Â 627Â 140</td>\n",
       "      <td>-0,36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02/04/2025</td>\n",
       "      <td>1Â 385</td>\n",
       "      <td>1Â 385</td>\n",
       "      <td>1Â 390</td>\n",
       "      <td>1Â 390</td>\n",
       "      <td>454</td>\n",
       "      <td>628Â 790</td>\n",
       "      <td>-0,36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01/04/2025</td>\n",
       "      <td>1Â 390</td>\n",
       "      <td>1Â 385</td>\n",
       "      <td>1Â 390</td>\n",
       "      <td>1Â 385</td>\n",
       "      <td>718</td>\n",
       "      <td>998Â 020</td>\n",
       "      <td>0,00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31/03/2025</td>\n",
       "      <td>1Â 390</td>\n",
       "      <td>1Â 390</td>\n",
       "      <td>1Â 390</td>\n",
       "      <td>1Â 390</td>\n",
       "      <td>9Â 490</td>\n",
       "      <td>13Â 191Â 100</td>\n",
       "      <td>0,00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date ClÃ´ture Plus bas Plus haut Ouverture Volume Titres Volume FCFA  \\\n",
       "0  11/04/2025   1Â 310    1Â 305     1Â 310     1Â 305         4Â 579   5Â 998Â 490   \n",
       "1  10/04/2025   1Â 305    1Â 305     1Â 325     1Â 325         1Â 401   1Â 828Â 305   \n",
       "2  09/04/2025   1Â 325    1Â 325     1Â 335     1Â 335        24Â 199  32Â 063Â 675   \n",
       "3  08/04/2025   1Â 350    1Â 350     1Â 370     1Â 370           599     808Â 650   \n",
       "4  07/04/2025   1Â 370    1Â 370     1Â 370     1Â 370         1Â 925   2Â 637Â 250   \n",
       "5  04/04/2025   1Â 370    1Â 370     1Â 370     1Â 370         2Â 174   2Â 978Â 380   \n",
       "6  03/04/2025   1Â 380    1Â 380     1Â 380     1Â 380         3Â 353   4Â 627Â 140   \n",
       "7  02/04/2025   1Â 385    1Â 385     1Â 390     1Â 390           454     628Â 790   \n",
       "8  01/04/2025   1Â 390    1Â 385     1Â 390     1Â 385           718     998Â 020   \n",
       "9  31/03/2025   1Â 390    1Â 390     1Â 390     1Â 390         9Â 490  13Â 191Â 100   \n",
       "\n",
       "  Variation %  \n",
       "0       0,38%  \n",
       "1      -1,51%  \n",
       "2      -1,85%  \n",
       "3      -1,46%  \n",
       "4       0,00%  \n",
       "5      -0,72%  \n",
       "6      -0,36%  \n",
       "7      -0,36%  \n",
       "8       0,00%  \n",
       "9       0,00%  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL cible\n",
    "url = \"https://www.sikafinance.com/marches/historiques/SDSC.ci\"\n",
    "\n",
    "# User-Agent pour Ã©viter les blocages\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# RequÃªte GET\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# RÃ©cupÃ©ration du tableau avec l'id tblhistos\n",
    "table = soup.find(\"table\", id=\"tblhistos\")\n",
    "\n",
    "# VÃ©rifier si le tableau est trouvÃ©\n",
    "if table:\n",
    "    # En-tÃªtes\n",
    "    headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "    # DonnÃ©es\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        cols = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "        if cols:\n",
    "            rows.append(cols)\n",
    "\n",
    "    # CrÃ©ation du DataFrame\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    # Affichage des 5 premiÃ¨res lignes\n",
    "    \n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3c1dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping AFRICA GLOBALÂ LOGISTICS (SDSC.ci)...\n",
      "Scraping AIR LIQUIDE CI (SIVC.ci)...\n",
      "Scraping BANK OF AFRICA BENIN (BOAB.bj)...\n",
      "Scraping BANK OF AFRICA BURKINA FASO (BOABF.bf)...\n",
      "Scraping BANK OF AFRICA CI (BOAC.ci)...\n",
      "Scraping BANK OF AFRICA MALI (BOAM.ml)...\n",
      "Scraping BANK OF AFRICA NIGER (BOAN.ne)...\n",
      "Scraping BANK OF AFRICA SENEGAL (BOAS.sn)...\n",
      "Scraping BERNABE (BNBC.ci)...\n",
      "Scraping BICICI (BICC.ci)...\n",
      "Scraping BRVM - AGRICULTURE (BRVMAG)...\n",
      "Scraping BRVM - AUTRES SECTEURS (BRVMAS)...\n",
      "Scraping BRVM - CONSOMMATION DE BASE (BRVM-CB)...\n",
      "Scraping BRVM - CONSOMMATION DISCRETIONNAIRE (BRVM-CD)...\n",
      "Scraping BRVM - DISTRIBUTION (BRVMDI)...\n",
      "Scraping BRVM - ENERGIE (BRVM-EN)...\n",
      "Scraping BRVM - FINANCE (BRVMFI)...\n",
      "Scraping BRVM - INDUSTRIE (BRVMIN)...\n",
      "Scraping BRVM - INDUSTRIELS (BRVM-IN)...\n",
      "Scraping BRVM - PRESTIGE (BRVMPR)...\n",
      "Scraping BRVM - PRINCIPAL (BRVMPA)...\n",
      "Scraping BRVM - SERVICES FINANCIERS (BRVM-SF)...\n",
      "Scraping BRVM - SERVICES PUBLICS (BRVMSP)...\n",
      "Scraping BRVM - SERVICES PUBLICS (BRVM-SP)...\n",
      "Scraping BRVM - TELECOMMUNICATIONS (BRVM-TEL)...\n",
      "Scraping BRVM - TRANSPORT (BRVMTR)...\n",
      "Scraping BRVM 30 (BRVM30)...\n",
      "Scraping BRVM COMPOSITE (BRVMC)...\n",
      "Scraping Capitalisation BRVM (CAPIBRVM)...\n",
      "Scraping CFAO CI (CFAC.ci)...\n",
      "Scraping CIE CI (CIEC.ci)...\n",
      "Scraping CORIS BANK INTERNATIONAL BF (CBIBF.bf)...\n",
      "Scraping CROWN SIEM (SEMC.ci)...\n",
      "Scraping ECOBANK CI (ECOC.ci)...\n",
      "Scraping ETI TG (ETIT.tg)...\n",
      "Scraping FILTISAC CI (FTSC.ci)...\n",
      "Scraping INDICE SIKAFINANCE (SIKAIDX)...\n",
      "Scraping LOTERIE NATIONALE DU BENIN (LNBB.bj)...\n",
      "Scraping MOVIS CI (SVOC.ci)...\n",
      "Scraping NEI CEDA CI (NEIC.ci)...\n",
      "Scraping NESTLE CI (NTLC.ci)...\n",
      "Scraping NSIA BANQUE (NSBC.ci)...\n",
      "Scraping ONATEL BF (ONTBF.bf)...\n",
      "Scraping ORAGROUP TOGO (ORGT.tg)...\n",
      "Scraping ORANGE CI (ORAC.ci)...\n",
      "Scraping PALMCI (PALC.ci)...\n",
      "Scraping SAFCA CI (SAFC.ci)...\n",
      "Scraping SAPH CI (SPHC.ci)...\n",
      "Scraping SERVAIR ABIDJAN CI (ABJC.ci)...\n",
      "Scraping SETAO CI (STAC.ci)...\n",
      "Scraping SGBCI (SGBC.ci)...\n",
      "Scraping SICABLE CI (CABC.ci)...\n",
      "Scraping SICOR (SICC.ci)...\n",
      "Scraping SIKA TOTAL RETURN (SIKATR)...\n",
      "Scraping SITAB (STBC.ci)...\n",
      "Scraping SMB CI (SMBC.ci)...\n",
      "Scraping SOCIETE IVOIRIENNE DE BANQUE CI (SIBC.ci)...\n",
      "Scraping SODECI (SDCC.ci)...\n",
      "Scraping SOGB (SOGC.ci)...\n",
      "Scraping SOLIBRA CI (SLBC.ci)...\n",
      "Scraping SONATEL (SNTS.sn)...\n",
      "Scraping SUCRIVOIRE (SCRC.ci)...\n",
      "Scraping TOTAL CI (TTLC.ci)...\n",
      "Scraping TOTAL SENEGAL (TTLS.sn)...\n",
      "Scraping TRACTAFRIC MOTORS CI (PRSC.ci)...\n",
      "Scraping UNILEVER CI (UNLC.ci)...\n",
      "Scraping UNIWAX CI (UNXC.ci)...\n",
      "Scraping VIVO ENERGY CI (SHEC.ci)...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "base_url = \"https://www.sikafinance.com/marches/historiques/\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# Ã‰tape 1 : RÃ©cupÃ©rer toutes les valeurs dâ€™option dans le sÃ©lecteur #dpShares\n",
    "homepage = requests.get(base_url + \"SDSC.ci\", headers=headers)\n",
    "soup_home = BeautifulSoup(homepage.content, \"html.parser\")\n",
    "\n",
    "select = soup_home.select_one(\"#dpShares\")\n",
    "\n",
    "# Liste des actions Ã  scraper (valeurs des options)\n",
    "options = select.find_all(\"option\")\n",
    "actions = [(opt.text.strip(), opt[\"value\"].strip()) for opt in options if opt[\"value\"].strip()]\n",
    "\n",
    "# Stockage global\n",
    "all_data = []\n",
    "\n",
    "for nom_action, valeur in actions:\n",
    "    print(f\"Scraping {nom_action} ({valeur})...\")\n",
    "\n",
    "    url = base_url + valeur\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    table = soup.find(\"table\", id=\"tblhistos\")\n",
    "\n",
    "    if table:\n",
    "        # RÃ©cupÃ©ration des en-tÃªtes\n",
    "        table_headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "\n",
    "        # RÃ©cupÃ©ration des lignes\n",
    "        rows = []\n",
    "        for tr in table.find_all(\"tr\")[1:]:\n",
    "            cols = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "            if cols:\n",
    "                rows.append(cols)\n",
    "\n",
    "        # DataFrame temporaire\n",
    "        df = pd.DataFrame(rows, columns=table_headers)\n",
    "        df[\"Action\"] = nom_action  # Ajouter nom de l'action\n",
    "        all_data.append(df)\n",
    "    else:\n",
    "        print(f\"âŒ Tableau non trouvÃ© pour {valeur}.\")\n",
    "\n",
    "    time.sleep(1)  # Petite pause pour Ã©viter d'Ãªtre bloquÃ©\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804ca09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Traitement de AFRICA GLOBAL LOGISTICS (SDSC.ci)...\n",
      "ğŸ” Traitement de AIR LIQUIDE CI (SIVC.ci)...\n",
      "ğŸ” Traitement de BANK OF AFRICA BENIN (BOAB.bj)...\n",
      "ğŸ” Traitement de BANK OF AFRICA BURKINA FASO (BOABF.bf)...\n",
      "ğŸ” Traitement de BANK OF AFRICA CI (BOAC.ci)...\n",
      "ğŸ” Traitement de BANK OF AFRICA MALI (BOAM.ml)...\n",
      "ğŸ” Traitement de BANK OF AFRICA NIGER (BOAN.ne)...\n",
      "ğŸ” Traitement de BANK OF AFRICA SENEGAL (BOAS.sn)...\n",
      "ğŸ” Traitement de BERNABE (BNBC.ci)...\n",
      "ğŸ” Traitement de BICICI (BICC.ci)...\n",
      "ğŸ” Traitement de BRVM - AGRICULTURE (BRVMAG)...\n",
      "ğŸ” Traitement de BRVM - AUTRES SECTEURS (BRVMAS)...\n",
      "ğŸ” Traitement de BRVM - CONSOMMATION DE BASE (BRVM-CB)...\n",
      "ğŸ” Traitement de BRVM - CONSOMMATION DISCRETIONNAIRE (BRVM-CD)...\n",
      "ğŸ” Traitement de BRVM - DISTRIBUTION (BRVMDI)...\n",
      "ğŸ” Traitement de BRVM - ENERGIE (BRVM-EN)...\n",
      "ğŸ” Traitement de BRVM - FINANCE (BRVMFI)...\n",
      "ğŸ” Traitement de BRVM - INDUSTRIE (BRVMIN)...\n",
      "ğŸ” Traitement de BRVM - INDUSTRIELS (BRVM-IN)...\n",
      "ğŸ” Traitement de BRVM - PRESTIGE (BRVMPR)...\n",
      "ğŸ” Traitement de BRVM - PRINCIPAL (BRVMPA)...\n",
      "ğŸ” Traitement de BRVM - SERVICES FINANCIERS (BRVM-SF)...\n",
      "ğŸ” Traitement de BRVM - SERVICES PUBLICS (BRVMSP)...\n",
      "ğŸ” Traitement de BRVM - SERVICES PUBLICS (BRVM-SP)...\n",
      "ğŸ” Traitement de BRVM - TELECOMMUNICATIONS (BRVM-TEL)...\n",
      "ğŸ” Traitement de BRVM - TRANSPORT (BRVMTR)...\n",
      "ğŸ” Traitement de BRVM 30 (BRVM30)...\n",
      "ğŸ” Traitement de BRVM COMPOSITE (BRVMC)...\n",
      "ğŸ” Traitement de Capitalisation BRVM (CAPIBRVM)...\n",
      "ğŸ” Traitement de CFAO CI (CFAC.ci)...\n",
      "ğŸ” Traitement de CIE CI (CIEC.ci)...\n",
      "ğŸ” Traitement de CORIS BANK INTERNATIONAL BF (CBIBF.bf)...\n",
      "ğŸ” Traitement de CROWN SIEM (SEMC.ci)...\n",
      "ğŸ” Traitement de ECOBANK CI (ECOC.ci)...\n",
      "ğŸ” Traitement de ETI TG (ETIT.tg)...\n",
      "ğŸ” Traitement de FILTISAC CI (FTSC.ci)...\n",
      "ğŸ” Traitement de INDICE SIKAFINANCE (SIKAIDX)...\n",
      "ğŸ” Traitement de LOTERIE NATIONALE DU BENIN (LNBB.bj)...\n",
      "ğŸ” Traitement de MOVIS CI (SVOC.ci)...\n",
      "ğŸ” Traitement de NEI CEDA CI (NEIC.ci)...\n",
      "ğŸ” Traitement de NESTLE CI (NTLC.ci)...\n",
      "ğŸ” Traitement de NSIA BANQUE (NSBC.ci)...\n",
      "ğŸ” Traitement de ONATEL BF (ONTBF.bf)...\n",
      "ğŸ” Traitement de ORAGROUP TOGO (ORGT.tg)...\n",
      "ğŸ” Traitement de ORANGE CI (ORAC.ci)...\n",
      "ğŸ” Traitement de PALMCI (PALC.ci)...\n",
      "ğŸ” Traitement de SAFCA CI (SAFC.ci)...\n",
      "ğŸ” Traitement de SAPH CI (SPHC.ci)...\n",
      "ğŸ” Traitement de SERVAIR ABIDJAN CI (ABJC.ci)...\n",
      "ğŸ” Traitement de SETAO CI (STAC.ci)...\n",
      "ğŸ” Traitement de SGBCI (SGBC.ci)...\n",
      "ğŸ” Traitement de SICABLE CI (CABC.ci)...\n",
      "ğŸ” Traitement de SICOR (SICC.ci)...\n",
      "ğŸ” Traitement de SIKA TOTAL RETURN (SIKATR)...\n",
      "ğŸ” Traitement de SITAB (STBC.ci)...\n",
      "ğŸ” Traitement de SMB CI (SMBC.ci)...\n",
      "ğŸ” Traitement de SOCIETE IVOIRIENNE DE BANQUE CI (SIBC.ci)...\n",
      "ğŸ” Traitement de SODECI (SDCC.ci)...\n",
      "ğŸ” Traitement de SOGB (SOGC.ci)...\n",
      "ğŸ” Traitement de SOLIBRA CI (SLBC.ci)...\n",
      "ğŸ” Traitement de SONATEL (SNTS.sn)...\n",
      "ğŸ” Traitement de SUCRIVOIRE (SCRC.ci)...\n",
      "ğŸ” Traitement de TOTAL CI (TTLC.ci)...\n",
      "ğŸ” Traitement de TOTAL SENEGAL (TTLS.sn)...\n",
      "ğŸ” Traitement de TRACTAFRIC MOTORS CI (PRSC.ci)...\n",
      "ğŸ” Traitement de UNILEVER CI (UNLC.ci)...\n",
      "ğŸ” Traitement de UNIWAX CI (UNXC.ci)...\n",
      "ğŸ” Traitement de VIVO ENERGY CI (SHEC.ci)...\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Dates souhaitÃ©es\n",
    "date_from = \"15/01/2025\"\n",
    "date_to = \"11/04/2025\"\n",
    "\n",
    "# Lancement du navigateur\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# AccÃ¨s Ã  la page principale\n",
    "driver.get(\"https://www.sikafinance.com/marches/historiques/SDSC.ci\")\n",
    "time.sleep(3)  # chargement initial\n",
    "\n",
    "# RÃ©cupÃ©ration des options du menu dÃ©roulant\n",
    "select_element = wait.until(EC.presence_of_element_located((By.ID, \"dpShares\")))\n",
    "select_html = Select(select_element)\n",
    "\n",
    "# RÃ©cupÃ©ration des paires (nom affichÃ©, valeur)\n",
    "options = [(opt.text.strip(), opt.get_attribute(\"value\").strip())\n",
    "           for opt in select_html.options if opt.get_attribute(\"value\").strip()]\n",
    "\n",
    "# Stockage des donnÃ©es globales\n",
    "all_data = []\n",
    "\n",
    "for nom_action, valeur in options:\n",
    "    print(f\"ğŸ” Traitement de {nom_action} ({valeur})...\")\n",
    "\n",
    "    # Recharger la page pour Ã©viter les conflits JS\n",
    "    driver.get(f\"https://www.sikafinance.com/marches/historiques/{valeur}\")\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        # Renseigner les dates\n",
    "        datefrom_input = wait.until(EC.presence_of_element_located((By.ID, \"datefrom\")))\n",
    "        dateto_input = driver.find_element(By.ID, \"dateto\")\n",
    "\n",
    "        datefrom_input.clear()\n",
    "        datefrom_input.send_keys(date_from)\n",
    "        dateto_input.clear()\n",
    "        dateto_input.send_keys(date_to)\n",
    "\n",
    "        # Cliquer sur \"OK\"\n",
    "        btn = driver.find_element(By.ID, \"btnChange\")\n",
    "        btn.click()\n",
    "\n",
    "        time.sleep(5)  # attendre le chargement des donnÃ©es\n",
    "\n",
    "        # Parser la page aprÃ¨s clic\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        table = soup.find(\"table\", id=\"tblhistos\")\n",
    "\n",
    "        if table:\n",
    "            headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "            rows = []\n",
    "            for tr in table.find_all(\"tr\")[1:]:\n",
    "                cols = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "                if cols:\n",
    "                    rows.append(cols)\n",
    "\n",
    "            df = pd.DataFrame(rows, columns=headers)\n",
    "            df[\"Action\"] = nom_action\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"âŒ Tableau non trouvÃ© pour {nom_action}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Erreur pour {nom_action}: {e}\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "# Fermeture du navigateur\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "248e9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connexion au cluster MongoDB Atlas\n",
    "client = MongoClient(\"mongodb+srv://amedbah2000:NQerjnFDI1xA8Dc1@cluster0.vbt1opf.mongodb.net/?retryWrites=true&w=majority\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DonnÃ©es envoyÃ©es Ã  MongoDB avec succÃ¨s.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SÃ©lection de la base de donnÃ©es et de la collection\n",
    "db = client[\"sika_finance\"]\n",
    "collection = db[\"historique_actions\"]\n",
    "\n",
    "# Structure des donnÃ©es par action\n",
    "if all_data:\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    grouped = final_df.groupby(\"Action\")\n",
    "    for nom_action, df_action in grouped:\n",
    "        historique = df_action.drop(columns=[\"Action\"]).to_dict(orient=\"records\")\n",
    "\n",
    "        # VÃ©rifie si l'action existe dÃ©jÃ  dans la base\n",
    "        existing = collection.find_one({\"action\": nom_action})\n",
    "        if existing:\n",
    "            # Mettre Ã  jour les donnÃ©es existantes (fusionner les historiques si besoin)\n",
    "            collection.update_one(\n",
    "                {\"action\": nom_action},\n",
    "                {\"$set\": {\"historique\": historique}}\n",
    "            )\n",
    "        else:\n",
    "            # InsÃ©rer une nouvelle action\n",
    "            collection.insert_one({\n",
    "                \"action\": nom_action,\n",
    "                \"historique\": historique\n",
    "            })\n",
    "\n",
    "    print(\"âœ… DonnÃ©es envoyÃ©es Ã  MongoDB avec succÃ¨s.\")\n",
    "else:\n",
    "    print(\"âŒ Aucune donnÃ©e Ã  envoyer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5d052",
   "metadata": {},
   "source": [
    "## Actu et communiquÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Scraping AFRICA GLOBALÂ LOGISTICS (SDSC.ci)...\n",
      "ğŸ” Scraping AIR LIQUIDE CI (SIVC.ci)...\n",
      "ğŸ” Scraping BANK OF AFRICA BENIN (BOAB.bj)...\n",
      "ğŸ” Scraping BANK OF AFRICA BURKINA FASO (BOABF.bf)...\n",
      "ğŸ” Scraping BANK OF AFRICA CI (BOAC.ci)...\n",
      "ğŸ” Scraping BANK OF AFRICA MALI (BOAM.ml)...\n",
      "ğŸ” Scraping BANK OF AFRICA NIGER (BOAN.ne)...\n",
      "ğŸ” Scraping BANK OF AFRICA SENEGAL (BOAS.sn)...\n",
      "ğŸ” Scraping BERNABE (BNBC.ci)...\n",
      "ğŸ” Scraping BICICI (BICC.ci)...\n",
      "ğŸ” Scraping BRVM - AGRICULTURE (BRVMAG)...\n",
      "ğŸ” Scraping BRVM - AUTRES SECTEURS (BRVMAS)...\n",
      "ğŸ” Scraping BRVM - CONSOMMATION DE BASE (BRVM-CB)...\n",
      "ğŸ” Scraping BRVM - CONSOMMATION DISCRETIONNAIRE (BRVM-CD)...\n",
      "ğŸ” Scraping BRVM - DISTRIBUTION (BRVMDI)...\n",
      "ğŸ” Scraping BRVM - ENERGIE (BRVM-EN)...\n",
      "ğŸ” Scraping BRVM - FINANCE (BRVMFI)...\n",
      "ğŸ” Scraping BRVM - INDUSTRIE (BRVMIN)...\n",
      "ğŸ” Scraping BRVM - INDUSTRIELS (BRVM-IN)...\n",
      "ğŸ” Scraping BRVM - PRESTIGE (BRVMPR)...\n",
      "ğŸ” Scraping BRVM - PRINCIPAL (BRVMPA)...\n",
      "ğŸ” Scraping BRVM - SERVICES FINANCIERS (BRVM-SF)...\n",
      "ğŸ” Scraping BRVM - SERVICES PUBLICS (BRVMSP)...\n",
      "ğŸ” Scraping BRVM - SERVICES PUBLICS (BRVM-SP)...\n",
      "ğŸ” Scraping BRVM - TELECOMMUNICATIONS (BRVM-TEL)...\n",
      "ğŸ” Scraping BRVM - TRANSPORT (BRVMTR)...\n",
      "ğŸ” Scraping BRVM 30 (BRVM30)...\n",
      "ğŸ” Scraping BRVM COMPOSITE (BRVMC)...\n",
      "ğŸ” Scraping Capitalisation BRVM (CAPIBRVM)...\n",
      "ğŸ” Scraping CFAO CI (CFAC.ci)...\n",
      "ğŸ” Scraping CIE CI (CIEC.ci)...\n",
      "ğŸ” Scraping CORIS BANK INTERNATIONAL BF (CBIBF.bf)...\n",
      "ğŸ” Scraping CROWN SIEM (SEMC.ci)...\n",
      "ğŸ” Scraping ECOBANK CI (ECOC.ci)...\n",
      "ğŸ” Scraping ETI TG (ETIT.tg)...\n",
      "ğŸ” Scraping FILTISAC CI (FTSC.ci)...\n",
      "ğŸ” Scraping INDICE SIKAFINANCE (SIKAIDX)...\n",
      "ğŸ” Scraping LOTERIE NATIONALE DU BENIN (LNBB.bj)...\n",
      "ğŸ” Scraping MOVIS CI (SVOC.ci)...\n",
      "ğŸ” Scraping NEI CEDA CI (NEIC.ci)...\n",
      "ğŸ” Scraping NESTLE CI (NTLC.ci)...\n",
      "ğŸ” Scraping NSIA BANQUE (NSBC.ci)...\n",
      "ğŸ” Scraping ONATEL BF (ONTBF.bf)...\n",
      "ğŸ” Scraping ORAGROUP TOGO (ORGT.tg)...\n",
      "ğŸ” Scraping ORANGE CI (ORAC.ci)...\n",
      "ğŸ” Scraping PALMCI (PALC.ci)...\n",
      "ğŸ” Scraping SAFCA CI (SAFC.ci)...\n",
      "ğŸ” Scraping SAPH CI (SPHC.ci)...\n",
      "ğŸ” Scraping SERVAIR ABIDJAN CI (ABJC.ci)...\n",
      "ğŸ” Scraping SETAO CI (STAC.ci)...\n",
      "ğŸ” Scraping SGBCI (SGBC.ci)...\n",
      "ğŸ” Scraping SICABLE CI (CABC.ci)...\n",
      "ğŸ” Scraping SICOR (SICC.ci)...\n",
      "ğŸ” Scraping SIKA TOTAL RETURN (SIKATR)...\n",
      "ğŸ” Scraping SITAB (STBC.ci)...\n",
      "ğŸ” Scraping SMB CI (SMBC.ci)...\n",
      "ğŸ” Scraping SOCIETE IVOIRIENNE DE BANQUE CI (SIBC.ci)...\n",
      "ğŸ” Scraping SODECI (SDCC.ci)...\n",
      "ğŸ” Scraping SOGB (SOGC.ci)...\n",
      "ğŸ” Scraping SOLIBRA CI (SLBC.ci)...\n",
      "ğŸ” Scraping SONATEL (SNTS.sn)...\n",
      "ğŸ” Scraping SUCRIVOIRE (SCRC.ci)...\n",
      "ğŸ” Scraping TOTAL CI (TTLC.ci)...\n",
      "ğŸ” Scraping TOTAL SENEGAL (TTLS.sn)...\n",
      "ğŸ” Scraping TRACTAFRIC MOTORS CI (PRSC.ci)...\n",
      "ğŸ” Scraping UNILEVER CI (UNLC.ci)...\n",
      "ğŸ” Scraping UNIWAX CI (UNXC.ci)...\n",
      "ğŸ” Scraping VIVO ENERGY CI (SHEC.ci)...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "base_url = \"https://www.sikafinance.com\"\n",
    "cot_url = base_url + \"/marches/cotation_\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# Ã‰tape 1 : RÃ©cupÃ©rer toutes les valeurs du sÃ©lecteur\n",
    "homepage = requests.get(cot_url + \"SDSC.ci\", headers=headers)\n",
    "soup_home = BeautifulSoup(homepage.content, \"html.parser\")\n",
    "\n",
    "select = soup_home.select_one(\"#dpShares\")\n",
    "options = select.find_all(\"option\")\n",
    "actions = [(opt.text.strip(), opt[\"value\"].strip()) for opt in options if opt[\"value\"].strip()]\n",
    "\n",
    "\n",
    "all_news = []\n",
    "all_communiques = []\n",
    "\n",
    "for nom_action, valeur in actions:\n",
    "    print(f\"ğŸ” Scraping {nom_action} ({valeur})...\")\n",
    "\n",
    "    url = cot_url + valeur\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    \n",
    "    # ğŸ“° ActualitÃ©s\n",
    "    actualites_div = soup.find(\"div\", class_=\"home_content\")\n",
    "    if actualites_div:\n",
    "        spans = actualites_div.find_all(\"span\", class_=\"sp1\")\n",
    "        links = actualites_div.find_all(\"a\", class_=\"lks\")\n",
    "        for span, link in zip(spans, links):\n",
    "            all_news.append({\n",
    "                \"Action\": nom_action,\n",
    "                \"Date\": span.text.strip(),\n",
    "                \"Titre\": link.text.strip(),\n",
    "                \"URL\": base_url + link[\"href\"]\n",
    "            })\n",
    "\n",
    "    # ğŸ“‘ CommuniquÃ©s (section suivante sur la page)\n",
    "    communiques_section = actualites_div.find_next(\"div\", class_=\"home_content\")\n",
    "    if communiques_section:\n",
    "        spans = communiques_section.find_all(\"span\", class_=\"sp1\")\n",
    "        links = communiques_section.find_all(\"a\", class_=\"lks\")\n",
    "        for span, link in zip(spans, links):\n",
    "            all_communiques.append({\n",
    "                \"Action\": nom_action,\n",
    "                \"Date\": span.text.strip(),\n",
    "                \"Titre\": link.text.strip(),\n",
    "                \"URL\": base_url + link[\"href\"]\n",
    "            })\n",
    "\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‘‰ RÃ©sultats\n",
    "df_news = pd.DataFrame(all_news)\n",
    "df_communiques = pd.DataFrame(all_communiques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75d9250d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DonnÃ©es insÃ©rÃ©es avec succÃ¨s dans la collection 'actus_communiques'.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# SÃ©lection de la base et de la collection\n",
    "db = client[\"sika_finance\"]\n",
    "collection = db[\"actus_communiques\"]\n",
    "\n",
    "# ğŸ‘‰ CrÃ©ation des DataFrames\n",
    "df_news = pd.DataFrame(all_news)\n",
    "df_communiques = pd.DataFrame(all_communiques)\n",
    "\n",
    "# Regrouper par action dans df_news\n",
    "actions_uniques = df_news[\"Action\"].unique()\n",
    "\n",
    "# Parcours de chaque action\n",
    "for action in actions_uniques:\n",
    "    # Filtrer les actualitÃ©s et communiquÃ©s pour cette action\n",
    "    actualites = df_news[df_news[\"Action\"] == action].drop(columns=[\"Action\"]).to_dict(orient=\"records\")\n",
    "    communiques = df_communiques[df_communiques[\"Action\"] == action].drop(columns=[\"Action\"]).to_dict(orient=\"records\")\n",
    "\n",
    "    # Supprimer l'existant si besoin\n",
    "    collection.delete_one({\"action\": action})\n",
    "\n",
    "    # Insertion dans MongoDB\n",
    "    collection.insert_one({\n",
    "        \"action\": action,\n",
    "        \"actualites\": actualites,\n",
    "        \"communiques\": communiques\n",
    "    })\n",
    "\n",
    "print(\"âœ… DonnÃ©es insÃ©rÃ©es avec succÃ¨s dans la collection 'actus_communiques'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52222e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944b694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ› RÃ©cupÃ©ration des cotations...\n",
      "âœ… AFRICA GLOBALÂ LOGISTICS mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '460,00'\n",
      "âœ… BANK OF AFRICA BENIN mis Ã  jour\n",
      "âœ… BANK OF AFRICA BURKINA FASO mis Ã  jour\n",
      "âœ… BANK OF AFRICA CI mis Ã  jour\n",
      "âœ… BANK OF AFRICA MALI mis Ã  jour\n",
      "âœ… BANK OF AFRICA NIGER mis Ã  jour\n",
      "âœ… BANK OF AFRICA SENEGAL mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '865,00'\n",
      "âœ… BICICI mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '222,91'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '661,74'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '117,46'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '98,55'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '404,35'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '126,51'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '115,18'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '139,29'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '117,67'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '122,03'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '157,18'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '113,20'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '777,90'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '99,60'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '93,97'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '328,58'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '144,66'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '287,19'\n",
      "âœ… Capitalisation BRVM mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '610,00'\n",
      "âœ… CIE CI mis Ã  jour\n",
      "âœ… CORIS BANK INTERNATIONAL BF mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '700,00'\n",
      "âœ… ECOBANK CI mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '15,00'\n",
      "âœ… FILTISAC CI mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '69,08'\n",
      "Erreur extraction cotations: could not convert string to float: '-'\n",
      "âœ… MOVIS CI mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '620,00'\n",
      "âœ… NESTLE CI mis Ã  jour\n",
      "âœ… NSIA BANQUE mis Ã  jour\n",
      "âœ… ONATEL BF mis Ã  jour\n",
      "âœ… ORAGROUP TOGO mis Ã  jour\n",
      "âœ… ORANGE CI mis Ã  jour\n",
      "âœ… PALMCI mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '700,00'\n",
      "âœ… SAPH CI mis Ã  jour\n",
      "âœ… SERVAIR ABIDJAN CI mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '480,00'\n",
      "âœ… SGBCI mis Ã  jour\n",
      "âœ… SICABLE CI mis Ã  jour\n",
      "âœ… SICOR mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '277,78'\n",
      "âœ… SITAB mis Ã  jour\n",
      "âœ… SMB CI mis Ã  jour\n",
      "âœ… SOCIETE IVOIRIENNE DE BANQUE CI mis Ã  jour\n",
      "âœ… SODECI mis Ã  jour\n",
      "âœ… SOGB mis Ã  jour\n",
      "âœ… SOLIBRA CI mis Ã  jour\n",
      "âœ… SONATEL mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '960,00'\n",
      "âœ… TOTAL CI mis Ã  jour\n",
      "âœ… TOTAL SENEGAL mis Ã  jour\n",
      "âœ… TRACTAFRIC MOTORS CI mis Ã  jour\n",
      "âœ… UNILEVER CI mis Ã  jour\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '390,00'\n",
      "Erreur extraction cotations: invalid literal for int() with base 10: '925,00'\n",
      "â³ Pause 15 minutes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 96\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# Attendre 15 minutes\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ³ Pause 15 minutes...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m15\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ•— Attente de 8h...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Connexion MongoDB\n",
    "db = client[\"sika_finance\"]\n",
    "collection = db[\"cotations\"]\n",
    "\n",
    "def extraire_cotations(soup):\n",
    "    cot1 = soup.find(\"div\", id=\"cot1c\")\n",
    "    if not cot1:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        prix = float(cot1.select_one(\".cot1u\").text.split()[0].replace('\\xa0', '').replace('XOF', '').replace(',', '.'))\n",
    "        variation = cot1.select_one(\".quote_up, .quote_down\").text.strip()\n",
    "        tables = cot1.find_all(\"table\")\n",
    "\n",
    "        values = [td.text.replace('\\xa0', '').strip() for table in tables for td in table.find_all(\"td\")[1::2]]\n",
    "\n",
    "        return {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"prix\": prix,\n",
    "            \"variation\": variation,\n",
    "            \"volume_titres\": float(values[0].replace(' ', '').replace(',', '.')),\n",
    "            \"volume_xof\": float(values[1].replace(' ', '').replace(',', '.')),\n",
    "            \"ouverture\": float(values[2].replace(' ', '').replace(',', '.')),\n",
    "            \"plus_haut\": float(values[3].replace(' ', '').replace(',', '.')),\n",
    "            \"plus_bas\": float(values[4].replace(' ', '').replace(',', '.')),\n",
    "            \"cloture_veille\": float(values[5].replace(' ', '').replace(',', '.')),\n",
    "            \"beta\": float(values[6].replace(',', '.')),\n",
    "            \"rsi\": float(values[7].replace(',', '.')),\n",
    "            \"capital_echange\": values[8],\n",
    "            \"valorisation\": values[9]\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Erreur extraction cotations:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "base_url = \"https://www.sikafinance.com\"\n",
    "cot_url = base_url + \"/marches/cotation_\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# Ã‰tape 1 : RÃ©cupÃ©rer toutes les valeurs du sÃ©lecteur\n",
    "homepage = requests.get(cot_url + \"SDSC.ci\", headers=headers)\n",
    "soup_home = BeautifulSoup(homepage.content, \"html.parser\")\n",
    "\n",
    "select = soup_home.select_one(\"#dpShares\")\n",
    "options = select.find_all(\"option\")\n",
    "actions = [(opt.text.strip(), opt[\"value\"].strip()) for opt in options if opt[\"value\"].strip()]\n",
    "\n",
    "# DÃ©finir l'heure d'ouverture et de fermeture du marchÃ©\n",
    "start = datetime.now().replace(hour=8, minute=0, second=0, microsecond=0)\n",
    "end = datetime.now().replace(hour=18, minute=30, second=0, microsecond=0)\n",
    "\n",
    "# Liste pour stocker les cotations pendant la journÃ©e\n",
    "all_cotations = []\n",
    "\n",
    "while datetime.now() < end:\n",
    "    if datetime.now() >= start:\n",
    "        print(\"âŒ› RÃ©cupÃ©ration des cotations...\")\n",
    "\n",
    "        # Liste temporaire pour les cotations de cette pÃ©riode\n",
    "        cotations_period = []\n",
    "\n",
    "        for nom_action, valeur in actions:\n",
    "            try:\n",
    "                url = cot_url + valeur\n",
    "                response = requests.get(url, headers=headers)\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "                cotation = extraire_cotations(soup)\n",
    "                if cotation:\n",
    "                    cotations_period.append({\n",
    "                        \"action\": nom_action,\n",
    "                        **cotation  # Ajoute les cotations extraites Ã  l'entrÃ©e\n",
    "                    })\n",
    "                    print(f\"âœ… {nom_action} mis Ã  jour\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Erreur lors de la mise Ã  jour de {nom_action}: {e}\")\n",
    "\n",
    "        if cotations_period:\n",
    "            # Ajouter les cotations de la pÃ©riode dans le DataFrame\n",
    "            df = pd.DataFrame(cotations_period)\n",
    "            all_cotations.append(df)\n",
    "        \n",
    "        # Attendre 15 minutes\n",
    "        print(\"â³ Pause 15 minutes...\")\n",
    "#     \"time.sleep(15 * 60)\n",
    "    else:\n",
    "        print(\"ğŸ•— Attente de 8h...\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "130762e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Toutes les cotations ont Ã©tÃ© insÃ©rÃ©es dans la base de donnÃ©es.\n"
     ]
    }
   ],
   "source": [
    "# Une fois la pÃ©riode terminÃ©e, concatÃ©ner les DataFrames collectÃ©s\n",
    "if all_cotations:\n",
    "    final_df = pd.concat(all_cotations, ignore_index=True)\n",
    "\n",
    "    # InsÃ©rer dans la base de donnÃ©es MongoDB\n",
    "    for _, row in final_df.iterrows():\n",
    "        collection.update_one(\n",
    "            {\"action\": row[\"action\"]},\n",
    "            {\"$push\": {\"cotations\": row.to_dict()}},  # Ajouter chaque cotation Ã  l'action correspondante\n",
    "            upsert=True\n",
    "        )\n",
    "    print(\"âœ… Toutes les cotations ont Ã©tÃ© insÃ©rÃ©es dans la base de donnÃ©es.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
